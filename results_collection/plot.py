import matplotlib.pyplot as plt
import numpy as np

x = range(1, 37)
y = [106.64442920684814, 35.86769366264343, 22.26021933555603, 16.970359086990356, 14.079394817352295, 12.077508449554443, 10.510358810424805, 9.545872211456299, 8.893243312835693, 8.480238676071167, 8.472532510757446, 8.452847719192505, 7.368035316467285, 7.181074619293213, 6.980992794036865, 7.518324136734009, 6.8059399127960205, 6.657598495483398, 6.52942681312561, 5.972899675369263, 6.032154560089111, 5.8210179805755615, 5.712779998779297, 5.679279327392578, 5.9212729930877686, 5.621538877487183, 5.604886293411255, 5.717190504074097, 5.406286239624023, 5.307825326919556, 5.700675010681152, 5.38849401473999, 5.186410427093506, 5.2720842361450195, 5.602853298187256, 5.334318399429321]

x2 = range(1, 17)
y2 = [76.22610783576965, 38.13218712806702, 25.515932321548462, 19.979902029037476, 16.846718788146973, 14.899056434631348, 13.03781509399414, 12.09388518333435, 11.723751544952393, 11.323432445526123, 10.815624237060547, 10.608385562896729, 10.380805253982544, 9.975727796554565, 9.82112979888916, 9.840501308441162]

plt.plot(x, y, label="aws", color="blue")
plt.plot(x2, y2, label="gcloud", color="red")
plt.title("Preprocessing performance across CPUs")
plt.xlabel("# of CPUs")
plt.ylabel("Runtime (s)")
plt.legend()
plt.show()